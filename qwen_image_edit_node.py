import json
import os
import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import random
from typing import Dict, List, Optional, Tuple
import folder_paths

# å¯¼å…¥Dashscope SDK
try:
    from dashscope import MultiModalConversation
    import dashscope
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("è­¦å‘Š: dashscope åº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope")

class QwenImageEditPlus:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (["qwen-image-edit-plus", "qwen-image-edit"], {
                    "default": "qwen-image-edit",
                    "label": "é€‰æ‹©æ¨¡å‹"
                }),
                "image1": ("IMAGE", {
                    "label": "å›¾åƒ1 (å¿…å¡«)"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "å›¾1ä¸­çš„å¥³ç”Ÿç©¿ç€å›¾2ä¸­çš„é»‘è‰²è£™å­æŒ‰å›¾3çš„å§¿åŠ¿åä¸‹"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": ""  # ç•™ç©ºåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
                }),
                "num_outputs": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 6,
                    "step": 1,
                    "display": "slider"
                }),
            },
            "optional": {
                "image2": ("IMAGE", {
                    "label": "å›¾åƒ2 (å¯é€‰)"
                }),
                "image3": ("IMAGE", {
                    "label": "å›¾åƒ3 (å¯é€‰)"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä½è´¨é‡"
                }),
                "prompt_extend": (["true", "false"], {
                    "default": "true"
                }),
                "watermark": (["true", "false"], {
                    "default": "false"
                }),
                "region": (["beijing", "singapore"], {
                    "default": "beijing"
                }),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate_images"
    CATEGORY = "ğŸ¦Š Qwen/Image Edit"
    OUTPUT_IS_LIST = (True,)
    
    def __init__(self):
        self.output_dir = folder_paths.get_temp_directory()
        self.type = "temp"
    
    def image_to_base64(self, image: torch.Tensor) -> str:
        """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64ç¼–ç çš„URLæ ¼å¼"""
        # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®èŒƒå›´å†…
        if image.dim() == 4:
            image = image[0]
        image = image.permute(2, 0, 1)  # HWC to CHW
        
        # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´èŒƒå›´
        image_np = image.cpu().numpy()
        if image_np.max() <= 1.0:
            image_np = (image_np * 255).astype(np.uint8)
        else:
            image_np = image_np.astype(np.uint8)
        
        # è½¬æ¢å›PILå›¾åƒ
        image_np = image_np.transpose(1, 2, 0)  # CHW to HWC
        pil_image = Image.fromarray(image_np)
        
        # ä¿å­˜åˆ°å†…å­˜å¹¶è½¬æ¢ä¸ºbase64
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        img_byte_arr = img_byte_arr.getvalue()
        
        # è½¬æ¢ä¸ºbase64 data URL
        base64_str = base64.b64encode(img_byte_arr).decode('utf-8')
        return f"data:image/png;base64,{base64_str}"
    
    def download_image(self, url: str) -> torch.Tensor:
        """ä»URLä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸ºComfyUIæ ¼å¼"""
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            # æ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(response.content))
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆç§»é™¤alphaé€šé“ï¼‰
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_np = np.array(image).astype(np.float32) / 255.0
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            image_tensor = torch.from_numpy(image_np)[None, ...]
            
            return image_tensor
            
        except Exception as e:
            raise Exception(f"ä¸‹è½½å›¾åƒå¤±è´¥: {str(e)}")
    
    def generate_images(self, model, image1, prompt, api_key, num_outputs, 
                       image2=None, image3=None, negative_prompt="ä½è´¨é‡",
                       prompt_extend="true", watermark="false", region="beijing", seed=-1):
        
        # æ£€æŸ¥dashscopeæ˜¯å¦å¯ç”¨
        if not DASHSCOPE_AVAILABLE:
            raise Exception("dashscope åº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope")
        
        # è·å–APIå¯†é’¥
        if not api_key:
            api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise Exception("è¯·æä¾›APIå¯†é’¥æˆ–åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DASHSCOPE_API_KEY")
        
        # è®¾ç½®åœ°åŸŸURL
        if region == "singapore":
            dashscope.base_http_api_url = 'https://dashscope-intl.aliyuncs.com/api/v1'
        else:
            dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å›¾åƒ
        input_images = []
        if image1 is not None:
            input_images.append(image1)
        if image2 is not None:
            input_images.append(image2)
        if image3 is not None:
            input_images.append(image3)
        
        if len(input_images) == 0:
            raise Exception("è‡³å°‘éœ€è¦æä¾›ä¸€å¼ è¾“å…¥å›¾åƒ")
        
        print(f"è¾“å…¥å›¾åƒæ•°é‡: {len(input_images)}")
        
        # è½¬æ¢è¾“å…¥å›¾åƒä¸ºbase64æ ¼å¼
        content = []
        for i, image in enumerate(input_images):
            if i >= 3:  # æœ€å¤š3å¼ è¾“å…¥å›¾åƒ
                break
            try:
                image_base64 = self.image_to_base64(image)
                content.append({"image": image_base64})
                print(f"å›¾åƒ{i+1}è½¬æ¢å®Œæˆ")
            except Exception as e:
                raise Exception(f"è½¬æ¢å›¾åƒ{i+1}å¤±è´¥: {str(e)}")
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        content.append({"text": prompt})
        
        # æ„å»ºæ¶ˆæ¯
        messages = [{
            "role": "user",
            "content": content
        }]
        
        # å‡†å¤‡è°ƒç”¨å‚æ•°
        call_kwargs = {
            "api_key": api_key,
            "model": model,
            "messages": messages,
            "stream": False,
            "n": num_outputs,
            "watermark": watermark == "true",
            "negative_prompt": negative_prompt,
            "prompt_extend": prompt_extend == "true",
        }
        
        # å¤„ç†seedå‚æ•°ï¼šä¿®å¤èŒƒå›´é—®é¢˜
        if seed != -1:
            # ç¡®ä¿seedåœ¨æœ‰æ•ˆèŒƒå›´å†…
            if seed > 2147483647:
                print(f"è­¦å‘Š: seedå€¼ {seed} è¶…å‡ºAPIé™åˆ¶(2147483647)ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸ºæœ‰æ•ˆå€¼")
                seed = seed % 2147483647  # ä½¿ç”¨å–æ¨¡ç¡®ä¿åœ¨èŒƒå›´å†…
            call_kwargs["seed"] = seed
        else:
            # å¦‚æœseedä¸º-1ï¼Œç”Ÿæˆä¸€ä¸ªéšæœºç§å­ï¼ˆåœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼‰
            random_seed = random.randint(0, 2147483647)
            call_kwargs["seed"] = random_seed
        
        print(f"APIè°ƒç”¨å‚æ•°: seed={call_kwargs.get('seed')}, num_outputs={num_outputs}, è¾“å…¥å›¾åƒæ•°={len(input_images)}")
        
        # è°ƒç”¨API
        try:
            print(f"æ­£åœ¨è°ƒç”¨ {model} APIï¼Œç”Ÿæˆ {num_outputs} å¼ å›¾åƒ...")
            response = MultiModalConversation.call(**call_kwargs)
            
            if response.status_code == 200:
                print("APIè°ƒç”¨æˆåŠŸ!")
                
                # ä¸‹è½½æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ
                output_images = []
                for i, content_item in enumerate(response.output.choices[0].message.content):
                    if "image" in content_item:
                        image_url = content_item["image"]
                        print(f"ä¸‹è½½å›¾åƒ {i+1}: {image_url}")
                        image_tensor = self.download_image(image_url)
                        output_images.append(image_tensor)
                
                if not output_images:
                    raise Exception("APIå“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ•°æ®")
                
                print(f"æˆåŠŸä¸‹è½½ {len(output_images)} å¼ å›¾åƒ")
                return (output_images,)
                
            else:
                error_msg = f"APIè°ƒç”¨å¤±è´¥:\n"
                error_msg += f"HTTPè¿”å›ç : {response.status_code}\n"
                error_msg += f"é”™è¯¯ç : {getattr(response, 'code', 'N/A')}\n"
                error_msg += f"é”™è¯¯ä¿¡æ¯: {getattr(response, 'message', 'N/A')}"
                
                # æ‰“å°å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                print(f"å®Œæ•´å“åº”: {json.dumps(response, indent=2, ensure_ascii=False)}")
                
                raise Exception(error_msg)
                
        except Exception as e:
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_details = str(e)
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                try:
                    error_json = json.loads(e.response.text)
                    error_details = json.dumps(error_json, indent=2, ensure_ascii=False)
                except:
                    error_details = e.response.text
            
            raise Exception(f"ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {error_details}")

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "QwenImageEditPlus": QwenImageEditPlus,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "QwenImageEditPlus": "ğŸ¦Š Qwen Image Edit Plus",
}

# ä½¿ç”¨è¯´æ˜
"""
æ›´æ–°è¯´æ˜:
1. ç°åœ¨æ”¯æŒ3å¼ ç‹¬ç«‹çš„å›¾åƒè¾“å…¥:
   - image1: å›¾åƒ1 (å¿…å¡«)
   - image2: å›¾åƒ2 (å¯é€‰)
   - image3: å›¾åƒ3 (å¯é€‰)

2. æä¾›äº†ä¸€ç§èŠ‚ç‚¹:
   - QwenImageEditPlus: å®Œæ•´åŠŸèƒ½ç‰ˆ

3. ä½¿ç”¨å»ºè®®:
   - å¦‚æœéœ€è¦æ‰€æœ‰é«˜çº§å‚æ•°ï¼Œä½¿ç”¨ QwenImageEditPlus

4. å·¥ä½œæµç¤ºä¾‹:
   Load Image 1 â†’ QwenImageEditPlus â†’ Save Image
   Load Image 2 â†—
   Load Image 3 â†—
"""
