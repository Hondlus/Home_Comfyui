import json
import os
import torch
import numpy as np
from PIL import Image
import io
import base64
import requests
import random
from typing import Dict, List, Optional, Tuple
import folder_paths

# å¯¼å…¥Dashscope SDK
try:
    from dashscope import MultiModalConversation
    import dashscope
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("è­¦å‘Š: dashscope åº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope")

class QwenImageEditPlus:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image1": ("IMAGE", {
                    "label": "å›¾åƒ1 (å¿…å¡«)"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "å›¾1ä¸­çš„å¥³ç”Ÿç©¿ç€å›¾2ä¸­çš„é»‘è‰²è£™å­æŒ‰å›¾3çš„å§¿åŠ¿åä¸‹"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": ""  # ç•™ç©ºåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
                }),
                "num_outputs": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 6,
                    "step": 1,
                    "display": "slider"
                }),
            },
            "optional": {
                "image2": ("IMAGE", {
                    "label": "å›¾åƒ2 (å¯é€‰)"
                }),
                "image3": ("IMAGE", {
                    "label": "å›¾åƒ3 (å¯é€‰)"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä½è´¨é‡"
                }),
                "prompt_extend": (["true", "false"], {
                    "default": "true"
                }),
                "watermark": (["true", "false"], {
                    "default": "false"
                }),
                "region": (["beijing", "singapore"], {
                    "default": "beijing"
                }),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate_images"
    CATEGORY = "ğŸ¦Š Qwen/Image Edit"
    OUTPUT_IS_LIST = (True,)
    
    def __init__(self):
        self.output_dir = folder_paths.get_temp_directory()
        self.type = "temp"
    
    def image_to_base64(self, image: torch.Tensor) -> str:
        """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64ç¼–ç çš„URLæ ¼å¼"""
        # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®èŒƒå›´å†…
        if image.dim() == 4:
            image = image[0]
        image = image.permute(2, 0, 1)  # HWC to CHW
        
        # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´èŒƒå›´
        image_np = image.cpu().numpy()
        if image_np.max() <= 1.0:
            image_np = (image_np * 255).astype(np.uint8)
        else:
            image_np = image_np.astype(np.uint8)
        
        # è½¬æ¢å›PILå›¾åƒ
        image_np = image_np.transpose(1, 2, 0)  # CHW to HWC
        pil_image = Image.fromarray(image_np)
        
        # ä¿å­˜åˆ°å†…å­˜å¹¶è½¬æ¢ä¸ºbase64
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        img_byte_arr = img_byte_arr.getvalue()
        
        # è½¬æ¢ä¸ºbase64 data URL
        base64_str = base64.b64encode(img_byte_arr).decode('utf-8')
        return f"data:image/png;base64,{base64_str}"
    
    def download_image(self, url: str) -> torch.Tensor:
        """ä»URLä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸ºComfyUIæ ¼å¼"""
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            # æ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(response.content))
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆç§»é™¤alphaé€šé“ï¼‰
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_np = np.array(image).astype(np.float32) / 255.0
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            image_tensor = torch.from_numpy(image_np)[None, ...]
            
            return image_tensor
            
        except Exception as e:
            raise Exception(f"ä¸‹è½½å›¾åƒå¤±è´¥: {str(e)}")
    
    def generate_images(self, image1, prompt, api_key, num_outputs, 
                       image2=None, image3=None, negative_prompt="ä½è´¨é‡",
                       prompt_extend="true", watermark="false", region="beijing", seed=-1):
        
        # æ£€æŸ¥dashscopeæ˜¯å¦å¯ç”¨
        if not DASHSCOPE_AVAILABLE:
            raise Exception("dashscope åº“æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope")
        
        # è·å–APIå¯†é’¥
        if not api_key:
            api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise Exception("è¯·æä¾›APIå¯†é’¥æˆ–åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DASHSCOPE_API_KEY")
        
        # è®¾ç½®åœ°åŸŸURL
        if region == "singapore":
            dashscope.base_http_api_url = 'https://dashscope-intl.aliyuncs.com/api/v1'
        else:
            dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å›¾åƒ
        input_images = []
        if image1 is not None:
            input_images.append(image1)
        if image2 is not None:
            input_images.append(image2)
        if image3 is not None:
            input_images.append(image3)
        
        if len(input_images) == 0:
            raise Exception("è‡³å°‘éœ€è¦æä¾›ä¸€å¼ è¾“å…¥å›¾åƒ")
        
        print(f"è¾“å…¥å›¾åƒæ•°é‡: {len(input_images)}")
        
        # è½¬æ¢è¾“å…¥å›¾åƒä¸ºbase64æ ¼å¼
        content = []
        for i, image in enumerate(input_images):
            if i >= 3:  # æœ€å¤š3å¼ è¾“å…¥å›¾åƒ
                break
            try:
                image_base64 = self.image_to_base64(image)
                content.append({"image": image_base64})
                print(f"å›¾åƒ{i+1}è½¬æ¢å®Œæˆ")
            except Exception as e:
                raise Exception(f"è½¬æ¢å›¾åƒ{i+1}å¤±è´¥: {str(e)}")
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        content.append({"text": prompt})
        
        # æ„å»ºæ¶ˆæ¯
        messages = [{
            "role": "user",
            "content": content
        }]
        
        # å‡†å¤‡è°ƒç”¨å‚æ•°
        call_kwargs = {
            "api_key": api_key,
            "model": "qwen-image-edit-plus",
            "messages": messages,
            "stream": False,
            "n": num_outputs,
            "watermark": watermark == "true",
            "negative_prompt": negative_prompt,
            "prompt_extend": prompt_extend == "true",
        }
        
        # å¤„ç†seedå‚æ•°ï¼šä¿®å¤èŒƒå›´é—®é¢˜
        if seed != -1:
            # ç¡®ä¿seedåœ¨æœ‰æ•ˆèŒƒå›´å†…
            if seed > 2147483647:
                print(f"è­¦å‘Š: seedå€¼ {seed} è¶…å‡ºAPIé™åˆ¶(2147483647)ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸ºæœ‰æ•ˆå€¼")
                seed = seed % 2147483647  # ä½¿ç”¨å–æ¨¡ç¡®ä¿åœ¨èŒƒå›´å†…
            call_kwargs["seed"] = seed
        else:
            # å¦‚æœseedä¸º-1ï¼Œç”Ÿæˆä¸€ä¸ªéšæœºç§å­ï¼ˆåœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼‰
            random_seed = random.randint(0, 2147483647)
            call_kwargs["seed"] = random_seed
        
        print(f"APIè°ƒç”¨å‚æ•°: seed={call_kwargs.get('seed')}, num_outputs={num_outputs}, è¾“å…¥å›¾åƒæ•°={len(input_images)}")
        
        # è°ƒç”¨API
        try:
            print(f"æ­£åœ¨è°ƒç”¨Qwen Image Edit Plus APIï¼Œç”Ÿæˆ {num_outputs} å¼ å›¾åƒ...")
            response = MultiModalConversation.call(**call_kwargs)
            
            if response.status_code == 200:
                print("APIè°ƒç”¨æˆåŠŸ!")
                
                # ä¸‹è½½æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒ
                output_images = []
                for i, content_item in enumerate(response.output.choices[0].message.content):
                    if "image" in content_item:
                        image_url = content_item["image"]
                        print(f"ä¸‹è½½å›¾åƒ {i+1}: {image_url}")
                        image_tensor = self.download_image(image_url)
                        output_images.append(image_tensor)
                
                if not output_images:
                    raise Exception("APIå“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ•°æ®")
                
                print(f"æˆåŠŸä¸‹è½½ {len(output_images)} å¼ å›¾åƒ")
                return (output_images,)
                
            else:
                error_msg = f"APIè°ƒç”¨å¤±è´¥:\n"
                error_msg += f"HTTPè¿”å›ç : {response.status_code}\n"
                error_msg += f"é”™è¯¯ç : {getattr(response, 'code', 'N/A')}\n"
                error_msg += f"é”™è¯¯ä¿¡æ¯: {getattr(response, 'message', 'N/A')}"
                
                # æ‰“å°å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                print(f"å®Œæ•´å“åº”: {json.dumps(response, indent=2, ensure_ascii=False)}")
                
                raise Exception(error_msg)
                
        except Exception as e:
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_details = str(e)
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                try:
                    error_json = json.loads(e.response.text)
                    error_details = json.dumps(error_json, indent=2, ensure_ascii=False)
                except:
                    error_details = e.response.text
            
            raise Exception(f"ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {error_details}")

# ä¸€ä¸ªæ›´ç®€å•çš„ç‰ˆæœ¬ï¼Œé€‚åˆå¤§å¤šæ•°ä½¿ç”¨åœºæ™¯
class QwenImageEdit3Inputs:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image1": ("IMAGE", {
                    "label": "å›¾åƒ1 (å‚è€ƒå›¾)"
                }),
                "image2": ("IMAGE", {
                    "label": "å›¾åƒ2 (å‚è€ƒå›¾)"
                }),
                "image3": ("IMAGE", {
                    "label": "å›¾åƒ3 (å‚è€ƒå›¾)"
                }),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "å›¾1ä¸­çš„å¥³ç”Ÿç©¿ç€å›¾2ä¸­çš„é»‘è‰²è£™å­æŒ‰å›¾3çš„å§¿åŠ¿åä¸‹"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": ""
                }),
                "num_outputs": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 6,
                    "step": 1,
                    "display": "slider"
                }),
            },
            "optional": {
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä½è´¨é‡"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate_images"
    CATEGORY = "ğŸ¦Š Qwen/Image Edit"
    OUTPUT_IS_LIST = (True,)
    
    def generate_images(self, image1, image2, image3, prompt, api_key, num_outputs, 
                       negative_prompt="ä½è´¨é‡"):
        """ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“ä¸º3å¼ è¾“å…¥å›¾åƒè®¾è®¡"""
        if not DASHSCOPE_AVAILABLE:
            raise Exception("dashscope åº“æœªå®‰è£…")
        
        if not api_key:
            api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise Exception("è¯·æä¾›APIå¯†é’¥")
        
        # è®¾ç½®åœ°åŸŸURLï¼ˆé»˜è®¤åŒ—äº¬ï¼‰
        dashscope.base_http_api_url = 'https://dashscope.aliyuncs.com/api/v1'
        
        # è½¬æ¢3å¼ è¾“å…¥å›¾åƒ
        content = []
        
        # è½¬æ¢å›¾åƒ1
        try:
            base64_1 = self.image_to_base64(image1)
            content.append({"image": base64_1})
        except Exception as e:
            raise Exception(f"è½¬æ¢å›¾åƒ1å¤±è´¥: {str(e)}")
        
        # è½¬æ¢å›¾åƒ2
        try:
            base64_2 = self.image_to_base64(image2)
            content.append({"image": base64_2})
        except Exception as e:
            raise Exception(f"è½¬æ¢å›¾åƒ2å¤±è´¥: {str(e)}")
        
        # è½¬æ¢å›¾åƒ3
        try:
            base64_3 = self.image_to_base64(image3)
            content.append({"image": base64_3})
        except Exception as e:
            raise Exception(f"è½¬æ¢å›¾åƒ3å¤±è´¥: {str(e)}")
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        content.append({"text": prompt})
        
        messages = [{
            "role": "user",
            "content": content
        }]
        
        # ä½¿ç”¨æœ€ç®€åŒ–çš„å‚æ•°è°ƒç”¨
        try:
            print(f"æ­£åœ¨è°ƒç”¨Qwen Image Edit Plus APIï¼Œä½¿ç”¨3å¼ è¾“å…¥å›¾åƒç”Ÿæˆ {num_outputs} å¼ è¾“å‡º...")
            
            response = MultiModalConversation.call(
                api_key=api_key,
                model="qwen-image-edit-plus",
                messages=messages,
                stream=False,
                n=num_outputs,
                watermark=False,
                negative_prompt=negative_prompt,
                prompt_extend=True,
            )
            
            if response.status_code == 200:
                output_images = []
                for i, content_item in enumerate(response.output.choices[0].message.content):
                    if "image" in content_item:
                        print(f"ä¸‹è½½è¾“å‡ºå›¾åƒ {i+1}")
                        image_tensor = self.download_image(content_item["image"])
                        output_images.append(image_tensor)
                
                if not output_images:
                    raise Exception("APIå“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ•°æ®")
                
                print(f"æˆåŠŸç”Ÿæˆ {len(output_images)} å¼ å›¾åƒ")
                return (output_images,)
            else:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {response.status_code}\n"
                error_msg += f"é”™è¯¯ä¿¡æ¯: {response.message}"
                raise Exception(error_msg)
                
        except Exception as e:
            raise Exception(f"ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {str(e)}")
    
    def image_to_base64(self, image: torch.Tensor) -> str:
        """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64"""
        if image.dim() == 4:
            image = image[0]
        image = image.permute(2, 0, 1)
        image_np = image.cpu().numpy()
        
        if image_np.max() <= 1.0:
            image_np = (image_np * 255).astype(np.uint8)
        else:
            image_np = image_np.astype(np.uint8)
        
        image_np = image_np.transpose(1, 2, 0)
        pil_image = Image.fromarray(image_np)
        
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        base64_str = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
        return f"data:image/png;base64,{base64_str}"
    
    def download_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾åƒ"""
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        image = Image.open(io.BytesIO(response.content))
        if image.mode != 'RGB':
            image = image.convert('RGB')
        image_np = np.array(image).astype(np.float32) / 255.0
        return torch.from_numpy(image_np)[None, ...]

# æ”¯æŒ1-3å¼ å›¾åƒçš„çµæ´»ç‰ˆæœ¬
class QwenImageEditFlexible:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "å›¾1ä¸­çš„å¥³ç”Ÿç©¿ç€å›¾2ä¸­çš„é»‘è‰²è£™å­æŒ‰å›¾3çš„å§¿åŠ¿åä¸‹"
                }),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": ""
                }),
                "num_outputs": ("INT", {
                    "default": 2,
                    "min": 1,
                    "max": 6,
                    "step": 1
                }),
            },
            "optional": {
                "image1": ("IMAGE", {
                    "label": "å›¾åƒ1"
                }),
                "image2": ("IMAGE", {
                    "label": "å›¾åƒ2"
                }),
                "image3": ("IMAGE", {
                    "label": "å›¾åƒ3"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä½è´¨é‡"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate_images"
    CATEGORY = "ğŸ¦Š Qwen/Image Edit"
    OUTPUT_IS_LIST = (True,)
    
    def generate_images(self, prompt, api_key, num_outputs, 
                       image1=None, image2=None, image3=None,
                       negative_prompt="ä½è´¨é‡"):
        """çµæ´»ç‰ˆæœ¬ï¼Œæ”¯æŒ1-3å¼ è¾“å…¥å›¾åƒ"""
        if not DASHSCOPE_AVAILABLE:
            raise Exception("dashscope åº“æœªå®‰è£…")
        
        if not api_key:
            api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise Exception("è¯·æä¾›APIå¯†é’¥")
        
        # æ”¶é›†æœ‰æ•ˆçš„è¾“å…¥å›¾åƒ
        input_images = []
        image_names = []
        
        if image1 is not None:
            input_images.append(image1)
            image_names.append("å›¾åƒ1")
        if image2 is not None:
            input_images.append(image2)
            image_names.append("å›¾åƒ2")
        if image3 is not None:
            input_images.append(image3)
            image_names.append("å›¾åƒ3")
        
        if len(input_images) == 0:
            raise Exception("è‡³å°‘éœ€è¦æä¾›ä¸€å¼ è¾“å…¥å›¾åƒ")
        
        print(f"è¾“å…¥å›¾åƒ: {len(input_images)}å¼  ({', '.join(image_names)})")
        
        # è½¬æ¢å›¾åƒ
        content = []
        for i, image in enumerate(input_images):
            try:
                base64_image = self.image_to_base64(image)
                content.append({"image": base64_image})
                print(f"{image_names[i]} è½¬æ¢å®Œæˆ")
            except Exception as e:
                raise Exception(f"è½¬æ¢{image_names[i]}å¤±è´¥: {str(e)}")
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        content.append({"text": prompt})
        
        messages = [{
            "role": "user",
            "content": content
        }]
        
        # è°ƒç”¨API
        try:
            print(f"æ­£åœ¨è°ƒç”¨APIï¼Œç”Ÿæˆ {num_outputs} å¼ å›¾åƒ...")
            
            response = MultiModalConversation.call(
                api_key=api_key,
                model="qwen-image-edit-plus",
                messages=messages,
                stream=False,
                n=num_outputs,
                watermark=False,
                negative_prompt=negative_prompt,
                prompt_extend=True,
            )
            
            if response.status_code == 200:
                output_images = []
                for i, content_item in enumerate(response.output.choices[0].message.content):
                    if "image" in content_item:
                        print(f"ä¸‹è½½è¾“å‡ºå›¾åƒ {i+1}")
                        image_tensor = self.download_image(content_item["image"])
                        output_images.append(image_tensor)
                
                print(f"æˆåŠŸç”Ÿæˆ {len(output_images)} å¼ å›¾åƒ")
                return (output_images,)
            else:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.message}")
                
        except Exception as e:
            raise Exception(f"ç”Ÿæˆå›¾åƒæ—¶å‡ºé”™: {str(e)}")
    
    def image_to_base64(self, image: torch.Tensor) -> str:
        """å°†ComfyUIå›¾åƒå¼ é‡è½¬æ¢ä¸ºbase64"""
        if image.dim() == 4:
            image = image[0]
        image = image.permute(2, 0, 1)
        image_np = image.cpu().numpy()
        
        if image_np.max() <= 1.0:
            image_np = (image_np * 255).astype(np.uint8)
        else:
            image_np = image_np.astype(np.uint8)
        
        image_np = image_np.transpose(1, 2, 0)
        pil_image = Image.fromarray(image_np)
        
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        base64_str = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
        return f"data:image/png;base64,{base64_str}"
    
    def download_image(self, url: str) -> torch.Tensor:
        """ä¸‹è½½å›¾åƒ"""
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        image = Image.open(io.BytesIO(response.content))
        if image.mode != 'RGB':
            image = image.convert('RGB')
        image_np = np.array(image).astype(np.float32) / 255.0
        return torch.from_numpy(image_np)[None, ...]

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "QwenImageEditPlus": QwenImageEditPlus,
    "QwenImageEdit3Inputs": QwenImageEdit3Inputs,
    "QwenImageEditFlexible": QwenImageEditFlexible,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "QwenImageEditPlus": "ğŸ¦Š Qwen Image Edit Plus",
    "QwenImageEdit3Inputs": "ğŸ¦Š Qwen 3å›¾ç¼–è¾‘",
    "QwenImageEditFlexible": "ğŸ¦Š Qwen çµæ´»ç¼–è¾‘",
}

# ä½¿ç”¨è¯´æ˜
"""
æ›´æ–°è¯´æ˜:
1. ç°åœ¨æ”¯æŒ3å¼ ç‹¬ç«‹çš„å›¾åƒè¾“å…¥:
   - image1: å›¾åƒ1 (å¿…å¡«)
   - image2: å›¾åƒ2 (å¯é€‰)
   - image3: å›¾åƒ3 (å¯é€‰)

2. æä¾›äº†ä¸‰ç§èŠ‚ç‚¹:
   - QwenImageEditPlus: å®Œæ•´åŠŸèƒ½ç‰ˆ
   - QwenImageEdit3Inputs: ä¸“ä¸º3å¼ è¾“å…¥å›¾åƒè®¾è®¡
   - QwenImageEditFlexible: çµæ´»ç‰ˆæœ¬ï¼Œæ”¯æŒ1-3å¼ å›¾åƒ

3. ä½¿ç”¨å»ºè®®:
   - å¦‚æœéœ€è¦å¤„ç†æ­£å¥½3å¼ å›¾åƒï¼Œä½¿ç”¨ QwenImageEdit3Inputs
   - å¦‚æœéœ€è¦çµæ´»å¤„ç†1-3å¼ å›¾åƒï¼Œä½¿ç”¨ QwenImageEditFlexible
   - å¦‚æœéœ€è¦æ‰€æœ‰é«˜çº§å‚æ•°ï¼Œä½¿ç”¨ QwenImageEditPlus

4. å·¥ä½œæµç¤ºä¾‹:
   Load Image 1 â†’ QwenImageEdit3Inputs â†’ Save Image
   Load Image 2 â†—
   Load Image 3 â†—
"""